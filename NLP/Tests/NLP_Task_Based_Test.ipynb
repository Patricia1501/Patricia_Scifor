{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment Analysis and Text Processing"
      ],
      "metadata": {
        "id": "q7qkEFMI3dNf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8Q0T-QetwCe",
        "outputId": "0af77169-96e3-4698-f402-52e7f149066e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install numpy matplotlib\n",
        "!{sys.executable} -m pip install svgling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQhbyjdmxbFh",
        "outputId": "89167ebc-ad94-4a0a-8b3a-f732db7ef761"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting svgling\n",
            "  Downloading svgling-0.4.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting svgwrite (from svgling)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Downloading svgling-0.4.0-py3-none-any.whl (23 kB)\n",
            "Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: svgwrite, svgling\n",
            "Successfully installed svgling-0.4.0 svgwrite-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "0K9l_ay9xiqm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwILY2mnxrpY",
        "outputId": "1b19a7ab-2c06-43b2-de2d-7d228191c7f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample paragraph\n",
        "paragraph = \"\"\"To be successful in any aspect of life, one needs to have strong dedication and work hard.\n",
        "               Opportunities will come and go, but you must decide the path to success.\n",
        "               To achieve something, you will have to cross the hurdles.\n",
        "               It would help if you crossed the difficulties with confidence and never gave up. If you give up, then all your efforts become useless.\"\"\"\n"
      ],
      "metadata": {
        "id": "dO9H7_k_xx4L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Processing: This involves cleaning and preparing the text for analysis\n",
        "# Tokenization\n",
        "tokens = word_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "MJHXRd4cymmE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]"
      ],
      "metadata": {
        "id": "2svhSJKeymis"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]"
      ],
      "metadata": {
        "id": "9txssRAWymgI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Tokens:\", tokens)\n",
        "print(\"Filtered Tokens:\", filtered_tokens)\n",
        "print(\"Lemmatized Tokens:\", lemmatized_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-pfXUbSymdU",
        "outputId": "c75d38e3-5781-44b6-a8fc-43ee3cf55c4a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens: ['To', 'be', 'successful', 'in', 'any', 'aspect', 'of', 'life', ',', 'one', 'needs', 'to', 'have', 'strong', 'dedication', 'and', 'work', 'hard', '.', 'Opportunities', 'will', 'come', 'and', 'go', ',', 'but', 'you', 'must', 'decide', 'the', 'path', 'to', 'success', '.', 'To', 'achieve', 'something', ',', 'you', 'will', 'have', 'to', 'cross', 'the', 'hurdles', '.', 'It', 'would', 'help', 'if', 'you', 'crossed', 'the', 'difficulties', 'with', 'confidence', 'and', 'never', 'gave', 'up', '.', 'If', 'you', 'give', 'up', ',', 'then', 'all', 'your', 'efforts', 'become', 'useless', '.']\n",
            "Filtered Tokens: ['successful', 'aspect', 'life', ',', 'one', 'needs', 'strong', 'dedication', 'work', 'hard', '.', 'Opportunities', 'come', 'go', ',', 'must', 'decide', 'path', 'success', '.', 'achieve', 'something', ',', 'cross', 'hurdles', '.', 'would', 'help', 'crossed', 'difficulties', 'confidence', 'never', 'gave', '.', 'give', ',', 'efforts', 'become', 'useless', '.']\n",
            "Lemmatized Tokens: ['successful', 'aspect', 'life', ',', 'one', 'need', 'strong', 'dedication', 'work', 'hard', '.', 'Opportunities', 'come', 'go', ',', 'must', 'decide', 'path', 'success', '.', 'achieve', 'something', ',', 'cross', 'hurdle', '.', 'would', 'help', 'crossed', 'difficulty', 'confidence', 'never', 'gave', '.', 'give', ',', 'effort', 'become', 'useless', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sentiment analysis\n",
        "\n",
        "Sentiment analysis is an NLP technique that uses machine learning to automatically analyze and classify the emotional tone of text data. It can identify positive, negative, or neutral sentiments in words and phrases from written reviews, social media posts, surveys, news articles, tweets, and blog posts.\n",
        "\n",
        "In sentiment analysis, polarity and subjectivity are two outputs that help understand the level of positivity or negativity and the amount of personal opinion in a text:<br>\n",
        "\n",
        "Polarity:<br>\n",
        "A value between -1 and 1 that indicates the level of positivity or negativity in a text. A score of -1 indicates negative sentiment, like \"disgusting\" or \"awful\", while a score of 1 indicates positive sentiment, like \"excellent\" or \"best\". A score of 0 indicates neutral sentiment.<br>\n",
        "\n",
        "Subjectivity:<br>\n",
        "A value between 0 and 1 that indicates the amount of personal opinion and factual information in a text. A score close to 1 indicates that the sentence has a lot of personal opinion, while a score closer to 0 indicates that the sentence is more objective.\n"
      ],
      "metadata": {
        "id": "WNqguhKU2f1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis\n",
        "blob = TextBlob(paragraph)\n",
        "sentiment = blob.sentiment\n",
        "\n",
        "print(\"Sentiment Analysis:\")\n",
        "print(\"Polarity:\", sentiment.polarity)\n",
        "print(\"Subjectivity:\", sentiment.subjectivity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG1N8Kfrymas",
        "outputId": "3507edea-9a03-4af3-9b9c-fac71762a1a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Analysis:\n",
            "Polarity: 0.11527777777777777\n",
            "Subjectivity: 0.4041666666666666\n"
          ]
        }
      ]
    }
  ]
}